!pip install mlxtend scikit-learn

import pandas as pd
 import numpy as np
 import plotly.express as px
 from sklearn.preprocessing import StandardScaler, MinMaxScaler
 from sklearn.utils import resample
 from sklearn.model_selection import train_test_split
 from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
 from mlxtend.plotting import plot_confusion_matrix
 from tqdm.notebook import tqdm
 import matplotlib.pyplot as plt
 import seaborn as sns
 import warnings
 warnings.filterwarnings("ignore")

 df = pd.read_csv("diabetes.csv")

 df

 df.describe().T

 df["Outcome"].value_counts()

sns.countplot(data=df, x=df["Outcome"])
 plt.show()

negative_data = df[df["Outcome"] == 0]
 positive_data = df[df["Outcome"] == 1]

positive_upsample = resample(positive_data,
 replace=True,
 n_samples=int(0.9*len(negative_data)),
 random_state=42)

new_df = negative_data
 new_df = new_df.append(positive_upsample)

new_df.shape

 new_df = new_df.sample(frac=1)

sns.countplot(data=new_df, x=new_df["Outcome"])
 plt.show()

x = new_df.drop("Outcome", axis=1)
 y = new_df[["Outcome"]]

scaler = MinMaxScaler()
 scaled_values = scaler.fit_transform(x)

 x_train, x_test, y_train, y_test = train_test_split(scaled_values, y, test_size

k_values = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21,
 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]
 accuracy_values = []

for i in tqdm(range(len(k_values))):
 model = KNeighborsClassifier(n_neighbors=k_values[i])
 model.fit(x_train, y_train)
 y_pred = model.predict(x_test)
 accuracy = metrics.accuracy_score(y_test, y_pred)
 accuracy_values.append(accuracy)

px.line(x=k_values, y=accuracy_values)

